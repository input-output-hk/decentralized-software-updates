
\section{Impact on performance}
\label{sec:impact-on-performance}

\subsection{Transaction Throughput}

An important measurement of a blockchain system's performance is the number of
transaction bytes per-second ($\mathit{TBPS}$) it can sustain. Unlike the more
commonly used metric, transactions per-second, this number is not dependent on
the chosen size of a transaction (which would allow to manipulate it at will by
choosing different transactions sizes). Running an update mechanism on the
blockchain should not result in a substantial performance degradation.
Therefore, in this section we estimate the impact on performance that the
proposed update mechanism will have on a system's TBPS. Our estimations are
based on \emph{worst case scenarios}, which allow us to determine upper bounds
for the performance impact of the update mechanism.

Given a payload size in bytes ($\mathit{psize}$) that needs to be stored in a
blockchain, and the blockchain's throughput measured in $\mathit{TBPS}$, we have
that the processing time ($\mathit{ptime}$) for the given payload can be
calculated as:
$$ \mathit{ptime} = \frac{\mathit{psize}}{\mathit{TBPS}}$$

The processing time needs to be considered relative to the duration of the
update process ($\mathit{duration}_u$). If we require $\mathit{ptime}$ seconds
to process a payload of $\mathit{psize}$ bytes, and the update process lasts for
$\mathit{duration}_u$ seconds, then the percentage of the blockchain system's
time that will be occupied processing the update payload can be
calculated as:
$$\mathit{ptime}_{\mathit{rel}} = 100\frac{\mathit{ptime}}{\mathit{duration}_u}$$

Equivalently, we can consider the percentage of the system's $\mathit{TBPS}$
that will be used by the update payload:
$$\mathit{usage}_{\mathit{pct}} = 100\frac{\mathit{psize}}{\mathit{TBPS} ~ \mathit{duration}_u}$$

In the analysis that follows, we consider only $\mathit{usage}_{\mathit{pct}}$,
as the value of $\mathit{ptime}_{\mathit{rel}}$ is the same.

An update consists of several phases (ideation, implementation, approval, and
activation). In each phase, there are three types of messages being sent:
commits, reveals, and votes.

% Why do we consider only the voting period:
Before the voting phases, where votes can be cast by the participants, each
update requires only two messages spread across two stability windows, needed
for transactions to stabilize in the chain. These stability windows are quite
large, e.g. in Cardano the window lasts for $2k$ slots, $k=2160$, and a slot
lasts for $20$ seconds, which means that the stability window is 1 day. As a
result, only two messages need to be transmitted for the commit-reveal phase
over a large period of time, which means that a blockchain system can easily
handle this. This leave us with the voting phase as the sole source for
performance degradation that can be caused by the update mechanism.

% Why do we consider phases in isolation
In addition, note that we only need to consider the additional load introduced
by the update mechanism during a single phase. It is in the voting period of
each phase where the system should be able to handle the additional load, since
the update mechanism introduces very little load between voting phases.

We define the worst-case scenario for a voting period in terms of
\begin{itemize}
\item number of participants ($n_p$), e.g. voters (note that in the worst case
  scenario everybody will vote, regardless of their stake, which means that the
  stake distribution is irrelevant for this analysis)
\item number of update proposals being voted at the same time ($n_c$), during the same
  period (note that in the worst case scenario multiple update proposals will
  coincide in the start and end of the voting period, otherwise the system would
  have a larger time interval to distribute the load).
\item number of time a participant changes her vote ($n_c$), per-update proposal
\end{itemize}
Then, we can calculate the worst case scenario for the number of bytes that need
to be transmitted as part of the vote payload ($\mathit{psize}_v$) as:
$$\mathit{psize}_v = s_v \mathit{n_p} n_r n_c$$

The size in bytes for $s_v$ was obtained by calculating the size CBOR
encoding~\cite{RFC7049} of the vote payload of our prototype. This payload
includes:
\begin{itemize}
\item The hash of the voted SIP. We use 32 bytes hashes, so considering the 1
  byte CBOR tag this gives us a total 33 bytes.
\item The confidence (for, against, reject), which can be encoded in 1 byte
  (which also included the CBOR tag).
\item The key of the voter. We use 32 bytes keys, so this give us a total of 33
  bytes, when we consider the CBOR tag.
\item The vote signature. We consider 64 bytes signatures, which are accompanied
  by a 32 bytes key. This results in 64 + 32 + 1 bytes required for the
  signature.
\end{itemize}
So a vote requires in total 164 bytes.

Table~\ref{fig:tab:worst-case-analysis-voting-period} shows the results of the
worst case analysis for different parameter values, where $\mathit{duration}_v$
is the number of voting days, which was used to calculate the voting period
duration. For this analysis we use the (very conservative) $\mathit{TBPS}$
estimate that Cardano can achieve: $25k$\footnote{TODO: we need a reference for
  this}.

\begin{table}[htb]
  \centering
  % NOTE: DO NOT EDIT THE TABLE BELOW: It was generated by the benchmarking program. See `formal-spec/bench` folder.
  \begin{tabular}{| r | r | r | r | r |}
    \hline
    $n_p$ & $n_r$ & $n_c$ & $\mathit{duration_v}$ & $\mathit{usage_{pct}}$\\
    \hline
    1000 & 2 & 1 & 7 & 0.002\\
    1000 & 2 & 5 & 7 & 0.011\\
    1000 & 2 & 10 & 7 & 0.022\\
    10000 & 2 & 1 & 7 & 0.022\\
    10000 & 2 & 5 & 7 & 0.108\\
    10000 & 2 & 10 & 7 & 0.217\\
    100000 & 2 & 1 & 7 & 0.217\\
    100000 & 2 & 5 & 7 & 1.085\\
    100000 & 2 & 10 & 7 & 2.169\\
    1000000 & 2 & 1 & 7 & 2.169\\
    1000000 & 2 & 5 & 7 & 10.847\\
    1000000 & 2 & 10 & 7 & 21.693\\
    1000000 & 2 & 10 & 14 & 10.847\\
    1000000 & 2 & 10 & 30 & 5.062\\
    10000000 & 2 & 1 & 7 & 21.693\\
    10000000 & 2 & 5 & 7 & 108.466\\
    10000000 & 2 & 10 & 7 & 216.931\\
    \hline
  \end{tabular}
  \caption[Worst-case analysis for voting period]{Worst-case analysis TBPS for a voting period}
  \label{fig:tab:worst-case-analysis-voting-period}
\end{table}

Figure~\ref{fig:usage-vs-participants} shows the worst case usage as a function
of the number of participants, assuming 10 concurrent update proposals, a 7 day
voting period, and each participant changing her vote twice.

\begin{figure}[htp]
  \centering

  \begin{tikzpicture}
    \begin{axis}[
      title={Participants vs usage percentage},
      xlabel={Participants},
      xmin=100.0,
      xmax=1.0e7,
      xmode=log,
      xtick={10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0, 1.0e7},
      ylabel={Usage percentage},
      ymin=0.0,
      ymax=250.0,
      ymode=log, 
      ytick={0.001, 0.01, 0.1, 1, 10, 100, 1000},
      legend pos=north west,
      ymajorgrids=true,
      grid style=dashed,
      ]
      \addplot[color=black] table {participants-vs-usage.dat};
    \end{axis}
  \end{tikzpicture}

  \caption{Worst case scenario analysis for system's usage with 10 concurrent update proposals}
  \label{fig:usage-vs-participants}
\end{figure}

We can see that the impact on the system's performance is negligible
even when we consider $100,000$ participants. Moreover, we see that 
the usage consumption percentage scales linearly in the number of 
participants, i.e., a 10 times increase in the number of participants 
will only increase 10 times the required usage percent. Also, if we 
double the throughput, then we can process a double amount of 
participants workload at the same time.
%
These results indicate that the update protocol will start degrading
the system performance \emph{only} past the 1,000,000 participants. 
Although this will require that the worst case conditions being met:
 10 SIP's being voted at the same time over the period of 7 days, 
where each participant votes twice.
%
In such case, relying on \emph{voting pools} (or \emph{expert pools}) 
becomes of crucial importance. In this way delegation of voting rights 
can help the update system is to scale beyond this number of 
participants. Alternatively, by increasing the duration of the vote 
period the impact on the system's performance can be mitigated.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% TODO: we need the revisit the section below considering the insight of
%% the section above.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Processing Time and Memory Consumption}
Clearly the most processing intesive task of the update mechanism 
is the tally phase. It is the phase where all the collected votes 
are counted in order to reach at a decision for a specific proposal. 

We start with a theoretical time complexity analysis where we 
assume a worst-case scenario, where we have $n$ participants that all
of them vote by submiting a single vote. Also we assume that we have
a single proposal, so that within a voting period, the number $n$ of participants coincides to the number of submitted ballots.

In the following we try to break up the operations during the tally phase.
 In the heart of the tally phase lies the following function call, 
 which is called for each proposal.
 
\begin{lstlisting}[language=Haskell, caption=Tally phase initial function call]
tallyStake confidence result ballot stakeDistribution adversarialStakeRatio =
  if stakeThreshold adversarialStakeRatio (totalStake stakeDistribution)
     <
     stakeOfKeys votingKeys stakeDistribution
  then Just result
  else Nothing
  where
    votingKeys = Map.filter (== confidence) ballot
\end{lstlisting}

\lstinline{Map.filter} \footnote{\href{url}{http://hackage.haskell.org/package/containers-0.6.2.1/docs/Data-Map-Strict.html\#g:25}}, is $O(n)$ so \lstinline{votingKeys} is $O(n)$, where $n$ is the number of ballots, 
which as we have said coincides to the number of participants. At 
this point, we have a single pass (loop) over $n$ ballots.

Furthermore, \lstinline{stakeOfKeys} makes the following calls:
\begin{lstlisting}[language=Haskell, caption=Code example]
stakeOfKeys
  keyMap
  StakeDistribution
  { stakeMap
  }
  = Map.foldl (+) 0 $ stakeMap `Map.intersection` keyMap
\end{lstlisting}

The $intersection$ function in the worst-case is $O(n)$\footnote{\href{url}{http://hackage.haskell.org/package/containers-0.6.2.1/docs/Data-Map-Strict.html\#v:intersection}}. Therefore this is a second pass
 (loop) over the data of length $n$.
\lstinline{foldl} is also $O(n)$\footnote{\href{url}{http://hackage.haskell.org/package/containers-0.6.2.1/docs/Data-Map-Strict.html\#v:foldl}}. This is a third pass (loop) over the data of 
length $n$. Thus from the above analysis we see that we have for 
a single proposal a call of \lstinline{tallyStake}, where in each
 such call we have three passes over the data of length $n$. So in total 
 for a single proposal we do $3$ passes over the data of length $n$. 
 That is $3n$ operations, which means that the tally time 
 complexity is $O(n)$. 

This result is also confirmed by the experimental evaluation 
shown in the graph below:

\begin{figure}[htp]
  \centering

  \begin{tikzpicture}
    \begin{axis}[
      title={Processing time (sec) vs Number of participants},
      xlabel={Participants},
      xmin=100.0,
      xmax=1.0e7,
      xmode=log,
      xtick={10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0, 1.0e7},
      ylabel={Processing time (sec)},
      ymin=0.0000001,
      ymax=10,
      ymode=log, 
      ytick={0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10},
      legend pos=north west,
      ymajorgrids=true,
      grid style=dashed,
      ]
      \addplot[color=black] table {participants-vs-elapsed_time.dat};
    \end{axis}
  \end{tikzpicture}

  \caption{Worst case scenario analysis for tally phase processing time}
  \label{fig:eltime-vs-participants}
\end{figure}

In Figure \ref{fig:eltime-vs-participants}, we see that the processing 
time increases linearly in the number of participants. In addition, 
we see that it takes almost one tenth of a second to process
 the votes of $1$ million participants. These results correspond to 
 a no-parallel execution of the tally algorithm on a i7 CPU laptop 
 with 32GB of RAM.

Finally, we present the measurements of the memory consumption 
during the tally phase. Again as the graph in 
Figure \ref{fig:memcons-vs-participants} shows, the memory 
allocated scales linearly in the number of participants. Moreover, our measurements show that the allocated memory essentially corresponds to the space required for storing the $256$ bit hashes of the public keys of the participants in a Haskell map structure\footnote{\href{url}{http://hackage.haskell.org/package/containers-0.6.2.1/docs/Data-Map-Strict.html}}.

\begin{figure}[htp]
  \centering

  \begin{tikzpicture}
    \begin{axis}[
      title={Memory consumed (MBs) vs Number of participants},
      xlabel={Participants},
      xmin=100.0,
      xmax=1.0e7,
      xmode=log,
      xtick={10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0, 1.0e7},
      ylabel={Memory consumed (MBs)},
      ymin=1,
      ymax=10000,
      ymode=log, 
      ytick={1, 10, 100, 1000, 10000},
      legend pos=north west,
      ymajorgrids=true,
      grid style=dashed,
      ]
      \addplot[color=black] table {participants-vs-memory_consumed.dat};
    \end{axis}
  \end{tikzpicture}

  \caption{Worst case scenario analysis for tally phase consumed memory}
  \label{fig:memcons-vs-participants}
\end{figure}

\section{Measurements specification} \label{sec:measurements}

In this section we want to describe an experimental evaluation of our proposed
update mechanism. This experimental evaluation will help to verify to what
degree our proposal fulfills non-functional requirements, such as the ones
described in section \ref{sec:non-func-reqs}.

\subsection{What to measure} \label{sec:what-to-measure} Our experimental
evaluation will mainly focus on the following metrics:

\paragraph{Transaction throughput}
\emph{High-level goal:} We want to evaluate the impact of the update protocol to
the transaction throughput of the blockchain system, i.e., to the number of
transactions that manage to get into a block in the unit of time.

Let be $N_{Tx}$ the average number of transactions that fit in a block. It is
defined as
%
$$N_{Tx} = \frac{\text{Block Size}}{\text{Avg Transaction Size}}$$
%
If a new block is issued every $T_B$ units of time, then we define the
\emph{transaction throughput} $Tx_{th}$ as the ratio
%
$$Tx_{th} = \frac{N_{Tx}}{T_B}$$
%
and we usually measure it in \emph{transactions per sec (tps)}. We want to
evaluate the impact of the number of users $N_u$ that actively participate in
the update mechanism to this metric.

\paragraph{Blockchain size}
\emph{High-level goal:} We want to evaluate the impact of storing update
transactions (i.e., transactions with an update payload) within a block, to the
number of common transactions that can be stored in the unit of storage.

Lets consider a blockchain system running a consensus protocol. At time point
$T_{start}$ we omit $k$ blocks from the end of the chain ($k$ is the security
parameter of the protocol) and mark the slot of the last block in the remaining
chain as $S_{start}$. We let the consensus protocol run for a fixed time window
of $T_w$ units of time until $T_{end}$ ($T_w = T{end} - T{start}$). Similarly,
we omit $k$ blocks from the end of the chain and mark the slot of the first
block in the remaining chain as $S_{end}$. We define the size of the chain
between slot $S_{start}$ and slot $S_{end}$ (included), as the \emph{blockchain
  size of time window} $T_w$ and call it $BSize_{T_w}$. Let $N_{T_w}$ be the
number of transactions stored in the chain of size $BSize_{T_w}$. We define the
\emph{number of transactions per unit of storage}, denoted $Tx_{s}$, as:
%
$$
Tx_{s} = \frac{\mathit{N_{T_w}}}{\mathit{BSize}}
$$
%
We want to evaluate the impact of the number of users $N_u$ that actively
participate in the update mechanism to this metric.

\paragraph{Update time to activation}
\emph{High-level goal:} we want to measure the total time to complete a software
update (i.e., the end-to-end elapsed time from submission-of-proposal to
activation) and evaluate how is this time impacted by the the number of active
users participating in the update protocol.

A software update (SU) starts its life with the submission into the blockchain
of a \emph{system improvement proposal} (SIP) and ends upon the activation of
the SU. We define the elapsed time that takes for a software update to activate
from start to finish, excluding the human delays (e.g., the time it takes for
the implementation of the software update) as the \emph{update time to
  activation} and note $T_{act}$. We want to evaluate the impact of the number
of users $N_u$ that actively participate in the update mechanism to this metric.

\paragraph{Processing time}
\emph{High-level goal:} we want to measure the computation load of the update
protocol and identify the most computation-heavy phases of the update protocol.

To this end, we will measure the processing time spent by the node, in each
\emph{distinct phase} of the decentralized software update \emph{lifecycle}, as
the number of active users $N_u$ participating in the update protocol increases.

\subsection{How to measure}
We consider two different approaches for conducting the measurements, depending
on whether we integrate with the Cardano blockchain and the underlying consensus
protocol. In the \emph{single node} alternative, we have a single node
implementation that does not need to run the consensus protocol; it only runs
the software updates protocol over a generated set of update events. In the
\emph{networked node} alternative, multiple nodes run the consensus protocol, as
well as the software updates protocol and communicate with each other.

In the single node case, the blockchain is generated by the generator process
and not by the node itself. The node reads each generated block and runs the
update protocol, since the block contains also transactions with update payload
apart from common transactions. So the update events stored in each block,
trigger a corresponding action from the part of the node that has to do with the
update protocol.

In the networked node case, the generator generates only transactions and not
blocks, which then transmits to the network to the running nodes. The nodes
listen to the network for these transactions and based on the rules of the
consensus protocol create blocks, which are then transmitted again to the
network for the other nodes to receive. Every node builds a local blockchain
based on the consensus protocol. We assume that apart from common transactions,
also transactions with update payload are generated, which trigger a node to run
the update protocol (as in the single-node case), but in this case this is done
along with the execution of the consensus protocol.

\subsubsection{Single node simulation}
\paragraph{Justification for the single node simulation}
In a realistic networked implementation of the update protocol, each participant
node will maintain a local blockchain consisting of common, as well as, update
transactions. We argue that for the specific measurements at hand (see section
\ref{sec:what-to-measure}) all the entailed information that we need, in order
to measure them correctly, has been incorporated in the end-product, which is
the local blockchain maintained by each node. Indeed, the number of common
transactions that managed to get through in the unit time of time, as well as
the number of common transactions that managed to get stored in a block, in the
presence of transactions with update payload, has been fully captured in the
produced blockchain. Therefore, we really do not need to actually run the
consensus layer in order to measure our metrics, but we need the result of the
consensus layer and that of the execution of the update protocol. As long as the
produced blockchain realistically represents such as an execution, the single
node measurements should be equivalent to the networked ones. The only
difference between the two approaches is that in the networked case, in some
cases (depends on the actual network setup) it is easier to produce a more
realistic blockchain end-product.

\paragraph{Set up}
We assume a single generator process. This generator process will simulate $N_u$
users running the software update protocol thus generating update events (i.e.,
update transactions) and $M_u$ users running the consensus protocol generating
common transactions.

We assume that a single user generates update transactions with a specific
weight compared to common transactions (e.g., 1 update transaction for every
1000 common transactions). As we increase the number of users actively
participating in the update protocol the weight that corresponds to the
generation of update events also increases. So the ratio of update transactions
to common transaction increases e.g., $r_u = 1/1000, 2/1000, ...$

The generator will produce a fixed length blockchain consisting of blocks that
store either common transactions, or update transactions. This blockchain will
trigger the node to run for a specific time window, either processing common
transactions, or running the update protocol. As the above ratio increases, we
expect to see the trace including more and more update transactions and less
common transactions. This is expected also, to impact at some point the running
time of the node, since the node will have to do more work due to the software
updates, but only at specific periods of the update protocol (e.g., the tally
phase) where the computation requirements are more intense.

It is important in the produced blockchain to simulate a realistic analogy of
stored transactions per block. To this end, in our size calculations we use the
actual Cardano \emph{maximum block size} $B_{max}$. In order to achieve a
realistic transactions per block analogy, we consider the
$TxPerBlock = \frac{Maximum Block Size}{Average Transaction Size}$, similarly
based on the Cardano benchmarks. So for example, if $TxPerBlock = 800$ and
$B_{max} = 1MB$, then we assume an abstract storage cost equal to $800$ units
for a block and an abstract storage cost of $1$ unit for a common transaction.
Then, for a transaction with an update payload, we consider an abstract storage
cost equal to $\frac{Actual Size of Update Payload}{B_{max}}$. In this way, our
abstract storage sizes simulate a realistic block size and more importantly, a
realistic analogy of common transactions and update transactions fitting in a
block.

\paragraph{Transaction throughput}
The number of common transactions included in a generated trace (i.e., a
blockchain consisting of common transactions and update transactions) of a
specific fixed length and corresponding to a specific ratio $r_u$, divided by
the total processing time of the node, will be the logical equivalent to the
transaction throughput in this setup. To compute the number of common
transactions, we only need to scan the produced blockchain. Similarly, to
compute the total processing time we multiply the number of blocks produced, by
the average time to produce a block (based on a Cardano benchmark measurement).

As more update transactions are added to the blockchain, the number of common
transactions stored in this fixed length blockchain will
decrease, %and also the processing time of the node will increase%
so we expect that the transaction throughput will decrease. We want to evaluate
experimentally the rate of this decrease as the $r_u$ ratio scales up.

\paragraph{Blockchain size}
The number of common transactions included in a generated trace (i.e., a
blockchain consisting of common transactions and update transactions) of a
specific fixed length and corresponding to a specific ratio $r_u$, divided by
the size of this blockchain, will be the measured Blockchain Size metric in this
setup. The number of common transactions is calculated as in the previous
metric. In order to compute the size of the produced blockchain, we take the
number of produced blocks and multiply them by the maximum size of a block
(based on the Cardano implementation).

As more update transactions are added to the blockchain the number of common
transactions per unit of storage is expected to decrease. We want to evaluate
experimentally the rate of this decrease as the $r_u$ ratio scales up.

\paragraph{Update time to activation}
We generate a fixed trace (i.e., a blockchain consisting of common transactions
and update transactions) of a specific fixed length and corresponding to a
specific ratio $r_u$. We scan this trace and for each SU encountered we
calculate the total elapsed time. To do this, we will use a \emph{representative
  transaction processing time} (e.g., time to block a transaction
$\approx 20 secs$), which will come from the Cardano benchmarks. For each update
transaction of a specific software update encountered, we add this
representative transaction processing time and thus calculate a total elapsed
time for the software update to be activated. Of course, we also need to take
into account other time periods like the stability windows, the voting periods
etc. So we will also need a \emph{representative time for a slot to be
  generated}, since all these periods correspond to specific number of slots.
Once we calculate the elapsed time for each software update, then we calculate
the 80th-percentile as the representative \emph{update time to activation}. As
more update transactions are added to the blockchain, this metric is expected to
increase. We want to evaluate experimentally the rate of this increase as the
$r_u$ ratio scales up.

\paragraph{Processing time}
We generate a fixed trace (i.e., a blockchain consisting of common transactions
and update transactions) of a specific fixed length and corresponding to a
specific ratio $r_u$. This trace will trigger the execution of the update
protocol by the node. For each distinct phase of the software update lifecycle,
we measure the actual processing time of the node. We want to evaluate the
processing time per distinct phase in order to identify the most
computation-heavy phases of the update protocol. As more update transactions are
added to the blockchain, the processing time is expected to increase, as more
work is done by the node. We want to evaluate experimentally the rate of this
increase as the $r_u$ ratio scales up.

\subsubsection{Networked node simulation}
\paragraph{Set up}
\paragraph{Transaction throughput}
\paragraph{Blockchain size}
\paragraph{Update time to activation}
